{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# EDA Rule Explorer\n",
    "\n",
    "Parse the **Event-Driven Ansible (EDA) rulebook** YAML and visualize event routing logic.\n",
    "\n",
    "## What EDA Does\n",
    "\n",
    "EDA consumes security events from Kafka and triggers Ansible playbooks to revoke certificates. The rulebook defines 87 rules that route events to the correct PKI hierarchy and CA level.\n",
    "\n",
    "```\n",
    "Kafka (security-events) \u2500\u2500\u25b6 EDA Rulebook (87 rules) \u2500\u2500\u25b6 Ansible Playbook \u2500\u2500\u25b6 Dogtag Revocation\n",
    "```\n",
    "\n",
    "## Rule Structure (87 Rules)\n",
    "\n",
    "| Component | Count | Description |\n",
    "|-----------|-------|-------------|\n",
    "| Dogtag rules | 81 | 27 event patterns \u00d7 3 PKI types (RSA/ECC/PQC) |\n",
    "| FreeIPA rules | 4 | Identity events also trigger FreeIPA revocation |\n",
    "| Logging rules | 2 | Event logging/debugging |\n",
    "\n",
    "### PKI Type Routing\n",
    "\n",
    "- **RSA** (default): Matches when `pki_type` is `\"rsa\"`, `null`, or not defined\n",
    "- **ECC**: Matches when `pki_type == \"ecc\"`\n",
    "- **PQC**: Matches when `pki_type == \"pqc\"`\n",
    "\n",
    "No catch-all fallback \u2014 every event type has explicit rules for all three PKI types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-docs",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "The rulebook YAML is mounted read-only at `/home/jovyan/rulebooks/` inside the Jupyter container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "RULEBOOK_DIR = Path(\"/home/jovyan/rulebooks\")\n",
    "RULEBOOK_FILE = RULEBOOK_DIR / \"security-events.yml\"\n",
    "\n",
    "print(f\"Rulebook: {RULEBOOK_FILE}\")\n",
    "print(f\"Exists: {RULEBOOK_FILE.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parse-header",
   "metadata": {},
   "source": [
    "## Parse Rulebook\n",
    "\n",
    "Load the YAML and extract rule name, condition, and action for each rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parse-rulebook",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = []\n",
    "\n",
    "if RULEBOOK_FILE.exists():\n",
    "    with open(RULEBOOK_FILE) as f:\n",
    "        rulebook = yaml.safe_load(f)\n",
    "\n",
    "    # Rulebook is a list of rulesets\n",
    "    if isinstance(rulebook, list):\n",
    "        for ruleset in rulebook:\n",
    "            ruleset_rules = ruleset.get(\"rules\", [])\n",
    "            for rule in ruleset_rules:\n",
    "                name = rule.get(\"name\", \"\")\n",
    "                condition = rule.get(\"condition\", \"\")\n",
    "                action = rule.get(\"action\", {})\n",
    "\n",
    "                # Extract event_type from condition\n",
    "                et_match = re.search(r'event_type\\s*==\\s*\"([^\"]+)\"', str(condition))\n",
    "                event_type = et_match.group(1) if et_match else \"\"\n",
    "\n",
    "                # Extract pki_type from condition\n",
    "                pki_match = re.search(r'pki_type\\s*==\\s*\"([^\"]+)\"', str(condition))\n",
    "                if pki_match:\n",
    "                    pki_type = pki_match.group(1)\n",
    "                elif \"pki_type is not defined\" in str(condition) or \"pki_type == null\" in str(condition):\n",
    "                    pki_type = \"rsa (default)\"\n",
    "                else:\n",
    "                    pki_type = \"\"\n",
    "\n",
    "                # Extract severity from condition\n",
    "                sev_match = re.search(r'severity\\s*==\\s*\"([^\"]+)\"', str(condition))\n",
    "                severity = sev_match.group(1) if sev_match else \"\"\n",
    "\n",
    "                # Extract playbook from action\n",
    "                playbook = \"\"\n",
    "                if isinstance(action, dict):\n",
    "                    rp = action.get(\"run_playbook\", {})\n",
    "                    if isinstance(rp, dict):\n",
    "                        playbook = rp.get(\"name\", \"\")\n",
    "\n",
    "                # Extract ca_level from extra_vars\n",
    "                ca_level = \"\"\n",
    "                if isinstance(action, dict):\n",
    "                    rp = action.get(\"run_playbook\", {})\n",
    "                    if isinstance(rp, dict):\n",
    "                        ev = rp.get(\"extra_vars\", {})\n",
    "                        if isinstance(ev, dict):\n",
    "                            ca_level = ev.get(\"ca_level\", \"\")\n",
    "\n",
    "                rules.append({\n",
    "                    \"name\": name,\n",
    "                    \"event_type\": event_type,\n",
    "                    \"pki_type\": pki_type,\n",
    "                    \"severity\": severity,\n",
    "                    \"ca_level\": ca_level,\n",
    "                    \"playbook\": playbook,\n",
    "                    \"condition\": str(condition)[:120],\n",
    "                })\n",
    "\n",
    "    print(f\"Parsed {len(rules)} rules from rulebook.\")\n",
    "else:\n",
    "    print(\"Rulebook file not found. Make sure the volume mount is configured.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "## Rule Summary\n",
    "\n",
    "Table of all rules with event type, PKI type, severity, target playbook, and CA level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rule-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "if rules:\n",
    "    df = pd.DataFrame(rules)\n",
    "    display(df[[\"name\", \"event_type\", \"pki_type\", \"severity\", \"ca_level\", \"playbook\"]])\n",
    "else:\n",
    "    print(\"No rules parsed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coverage-header",
   "metadata": {},
   "source": [
    "## Coverage Matrix\n",
    "\n",
    "Which event_type \u00d7 pki_type combinations have rules? A complete matrix should show coverage for all 26 event types across all 3 PKI types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coverage-matrix",
   "metadata": {},
   "outputs": [],
   "source": [
    "if rules:\n",
    "    df = pd.DataFrame(rules)\n",
    "    # Filter to rules with event_type (skip logging/meta rules)\n",
    "    df_typed = df[df[\"event_type\"] != \"\"].copy()\n",
    "\n",
    "    if not df_typed.empty:\n",
    "        # Normalize pki_type for the matrix\n",
    "        df_typed[\"pki_normalized\"] = df_typed[\"pki_type\"].apply(\n",
    "            lambda x: \"rsa\" if \"rsa\" in str(x).lower() else x\n",
    "        )\n",
    "        # Create coverage matrix\n",
    "        df_typed[\"has_rule\"] = \"YES\"\n",
    "        pivot = df_typed.pivot_table(\n",
    "            index=\"event_type\", columns=\"pki_normalized\",\n",
    "            values=\"has_rule\", aggfunc=\"first\", fill_value=\"-\"\n",
    "        )\n",
    "        # Reorder columns\n",
    "        for col_order in [[\"rsa\", \"ecc\", \"pqc\"], [\"rsa\", \"ecc\"], [\"rsa\"]]:\n",
    "            available = [c for c in col_order if c in pivot.columns]\n",
    "            if available:\n",
    "                pivot = pivot[available]\n",
    "                break\n",
    "\n",
    "        covered = (pivot == \"YES\").sum().sum()\n",
    "        total = pivot.shape[0] * pivot.shape[1]\n",
    "        print(f\"Coverage: {covered}/{total} cells ({covered/total*100:.0f}%)\")\n",
    "        print(f\"Event types: {pivot.shape[0]}, PKI types: {pivot.shape[1]}\")\n",
    "        display(pivot)\n",
    "    else:\n",
    "        print(\"No typed rules found.\")\n",
    "else:\n",
    "    print(\"No rules parsed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "category-header",
   "metadata": {},
   "source": [
    "## Rules by Category\n",
    "\n",
    "Group rules by event category and show counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rules-by-category",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = {\n",
    "    \"Original\": [\"malware_detection\", \"credential_theft\", \"ransomware\",\n",
    "                 \"c2_communication\", \"lateral_movement\", \"privilege_escalation\",\n",
    "                 \"suspicious_script\"],\n",
    "    \"PKI/Cert\": [\"key_compromise\", \"geo_anomaly\", \"compliance_violation\",\n",
    "                 \"mitm_detected\", \"rogue_ca\"],\n",
    "    \"IoT\": [\"firmware_integrity\", \"device_cloning\", \"iot_anomaly\",\n",
    "            \"protocol_attack\"],\n",
    "    \"Identity\": [\"impossible_travel\", \"service_account_abuse\",\n",
    "                 \"mfa_bypass\", \"kerberoasting\"],\n",
    "    \"Network\": [\"tls_downgrade\", \"ct_log_mismatch\", \"ocsp_bypass\"],\n",
    "    \"SIEM\": [\"data_exfiltration\", \"unauthorized_access\", \"certificate_misuse\"],\n",
    "}\n",
    "\n",
    "# Reverse lookup\n",
    "event_to_cat = {}\n",
    "for cat, events in CATEGORIES.items():\n",
    "    for e in events:\n",
    "        event_to_cat[e] = cat\n",
    "\n",
    "if rules:\n",
    "    df = pd.DataFrame(rules)\n",
    "    df[\"category\"] = df[\"event_type\"].map(event_to_cat).fillna(\"Other\")\n",
    "\n",
    "    cat_counts = df.groupby(\"category\").agg(\n",
    "        rules=(\"name\", \"count\"),\n",
    "        event_types=(\"event_type\", \"nunique\"),\n",
    "    ).sort_values(\"rules\", ascending=False)\n",
    "\n",
    "    print(\"Rules by Category:\")\n",
    "    display(cat_counts)\n",
    "else:\n",
    "    print(\"No rules parsed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trace-header",
   "metadata": {},
   "source": [
    "## Event Trace\n",
    "\n",
    "Given an event type and PKI type, show which rule matches and what playbook runs. **Change `TRACE_EVENT` and `TRACE_PKI` below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "event-trace",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRACE_EVENT = \"key_compromise\"   # any of the 26 event types\n",
    "TRACE_PKI = \"rsa\"                # rsa, ecc, pqc\n",
    "\n",
    "if rules:\n",
    "    df = pd.DataFrame(rules)\n",
    "    # Match event type\n",
    "    matches = df[df[\"event_type\"] == TRACE_EVENT]\n",
    "    # Match PKI type\n",
    "    pki_matches = matches[\n",
    "        matches[\"pki_type\"].str.contains(TRACE_PKI, case=False, na=False)\n",
    "    ]\n",
    "\n",
    "    print(f\"Event trace: event_type='{TRACE_EVENT}', pki_type='{TRACE_PKI}'\")\n",
    "    print(f\"Matching rules: {len(pki_matches)}\")\n",
    "\n",
    "    if not pki_matches.empty:\n",
    "        for _, row in pki_matches.iterrows():\n",
    "            print(f\"\\n  Rule: {row['name']}\")\n",
    "            print(f\"  Severity: {row['severity'] or 'any'}\")\n",
    "            print(f\"  CA Level: {row['ca_level'] or 'default'}\")\n",
    "            print(f\"  Playbook: {row['playbook']}\")\n",
    "    else:\n",
    "        print(\"No matching rules found.\")\n",
    "        if not matches.empty:\n",
    "            print(f\"\\nRules exist for event_type='{TRACE_EVENT}' with these PKI types:\")\n",
    "            print(f\"  {matches['pki_type'].unique().tolist()}\")\n",
    "else:\n",
    "    print(\"No rules parsed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "routing-header",
   "metadata": {},
   "source": [
    "## CA Level Routing\n",
    "\n",
    "Which event types route to which CA levels? Shows the default CA level assigned by the rulebook `extra_vars`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca-routing",
   "metadata": {},
   "outputs": [],
   "source": [
    "if rules:\n",
    "    df = pd.DataFrame(rules)\n",
    "    # Filter to rules with event_type and ca_level\n",
    "    df_routed = df[(df[\"event_type\"] != \"\") & (df[\"ca_level\"] != \"\")].copy()\n",
    "\n",
    "    if not df_routed.empty:\n",
    "        # Show unique event_type -> ca_level mappings\n",
    "        routing = df_routed.groupby(\"event_type\")[\"ca_level\"].apply(\n",
    "            lambda x: \", \".join(sorted(set(x)))\n",
    "        ).reset_index()\n",
    "        routing.columns = [\"event_type\", \"ca_levels\"]\n",
    "\n",
    "        # Add category\n",
    "        routing[\"category\"] = routing[\"event_type\"].map(event_to_cat).fillna(\"Other\")\n",
    "        routing = routing.sort_values([\"category\", \"event_type\"])\n",
    "\n",
    "        print(\"CA Level Routing:\")\n",
    "        display(routing.set_index(\"event_type\")[[\"category\", \"ca_levels\"]])\n",
    "    else:\n",
    "        print(\"No CA level routing data found.\")\n",
    "else:\n",
    "    print(\"No rules parsed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}